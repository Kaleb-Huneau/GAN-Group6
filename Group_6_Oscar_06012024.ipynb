{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaleb-Huneau/GAN-Group6/blob/Reduced-images/Group_6_Oscar_06012024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section\n",
        "# Run the code"
      ],
      "metadata": {
        "id": "LKcdtcwx8vdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Kaleb-Huneau/GAN-Group6.git"
      ],
      "metadata": {
        "id": "vMTlffe6Oou0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28b86ce-0989-42f7-f194-7f0d119d12e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GAN-Group6'...\n",
            "remote: Enumerating objects: 6769, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 6769 (delta 7), reused 26 (delta 7), pack-reused 6743\u001b[K\n",
            "Receiving objects: 100% (6769/6769), 159.34 MiB | 34.22 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Updating files: 100% (7032/7032), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ua2PwQB_X-ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RXmaBVEmhKqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Kaggle](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data)"
      ],
      "metadata": {
        "id": "owFM6k6oYDDX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F7le-Ad8QBFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing: for the brain MRI dataset [Brain tumor MRI](https://github.com/masoudnick/Brain-Tumor-MRI-Classification/blob/main/Preprocessing.py)\n"
      ],
      "metadata": {
        "id": "iOPMrqb4G1zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_directory(PATH):\n",
        "\tif not os.path.exists(PATH):\n",
        "\t\tos.mkdir(PATH)\n",
        "\n",
        "def crop_img(img):\n",
        "\t\"\"\"\n",
        "\tFinds the extreme points on the image and crops the rectangular out of them\n",
        "\t\"\"\"\n",
        "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\tgray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "\t# threshold the image, then perform a series of erosions +\n",
        "\t# dilations to remove any small regions of noise\n",
        "\tthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "\tthresh = cv2.erode(thresh, None, iterations=2)\n",
        "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "\t# find contours in thresholded image, then grab the largest one\n",
        "\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\tcnts = imutils.grab_contours(cnts)\n",
        "\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t# find the extreme points\n",
        "\textLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "\textRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "\textTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "\textBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\tADD_PIXELS = 0\n",
        "\tnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "\n",
        "\treturn new_img\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\ttraining = 'GAN-Group6/Dataset/Training'\n",
        "\ttesting = 'GAN-Group6/Dataset/Testing'\n",
        "\n",
        "\tmake_directory(training)\n",
        "\tmake_directory(testing)\n",
        "\n",
        "\tIMG_SIZE = 28\n",
        "\n",
        "\t# Now, list the directories after creating them\n",
        "\ttraining_dir = os.listdir(training)\n",
        "\ttesting_dir = os.listdir(testing)\n",
        "\ttumors = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "\n",
        "\tfor dir in tumors:\n",
        "\t\t\tsave_path = 'cleaned4/Training/' + dir\n",
        "\t\t\tpath = os.path.join(training, dir)\n",
        "\t\t\timage_dir = os.listdir(path)\n",
        "\t\t\tfor img in image_dir:\n",
        "\t\t\t\t\timage = cv2.imread(os.path.join(path, img))\n",
        "\t\t\t\t\tnew_img = crop_img(image)\n",
        "\n",
        "\t\t\t\t\tnew_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\t\tnew_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t\t\tcv2.imwrite('gray_image.jpg', new_img)\n",
        "\n",
        "\t\t\t\t\tnew_imgnp = np.array(new_imgnp)\n",
        "\t\t\t\t\tnew_imgnp = new_imgnp.reshape(28,28,1)\n",
        "\t\t\t\t\t#new\n",
        "\t\t\t\t\tif not os.path.exists(save_path):\n",
        "\t\t\t\t\t\t\tos.makedirs(save_path)\n",
        "\t\t\t\t\tcv2.imwrite(os.path.join(save_path, img), new_imgnp)\n",
        "\n",
        "\tfor dir in tumors:\n",
        "\t\t\tsave_path = 'cleaned4/Testing/' + dir\n",
        "\t\t\tpath = os.path.join(testing, dir)\n",
        "\t\t\timage_dir = os.listdir(path)\n",
        "\t\t\tfor img in image_dir:\n",
        "\t\t\t\t\timage = cv2.imread(os.path.join(path, img))\n",
        "\t\t\t\t\tnew_img = crop_img(image)\n",
        "\n",
        "\t\t\t\t\tnew_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\t\tnew_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t\t\tcv2.imwrite('gray_image.jpg', new_img)\n",
        "\n",
        "\t\t\t\t\tnew_imgnp = np.array(new_imgnp)\n",
        "\t\t\t\t\tnew_imgnp = new_imgnp.reshape(28,28,1)\n",
        "\t\t\t\t\t#new\n",
        "\t\t\t\t\tif not os.path.exists(save_path):\n",
        "\t\t\t\t\t\t\tos.makedirs(save_path)\n",
        "\t\t\t\t\tcv2.imwrite(os.path.join(save_path, img), new_imgnp)\n"
      ],
      "metadata": {
        "id": "s-vPtX0IGxqA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing to see if alterations work"
      ],
      "metadata": {
        "id": "0rK2I8q2ESOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#img2 = np.asarray(plt.imread(\"cleaned2/Testing/notumor/Tr-noTr_0003.jpg\", format='jpg'))\n",
        "\n",
        "'''\n",
        "new_img = []\n",
        "for i in range(28):\n",
        "  for j in range(28):\n",
        "    new_img.append(img[i][j][0])\n",
        "\n",
        "new_img = img[:, :, 0]\n",
        "\n",
        "new_img = np.array(new_img)\n",
        "new_img = new_img.reshape(28,28,1)\n",
        "plt.imshow(new_img, cmap='gray')\n",
        "'''\n",
        "\n",
        "#img2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "VxADjt9eER0H",
        "outputId": "06952321-2ee0-46ec-ec1c-3fd6233993b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nnew_img = []\\nfor i in range(28):\\n  for j in range(28):\\n    new_img.append(img[i][j][0])\\n\\nnew_img = img[:, :, 0]\\n\\nnew_img = np.array(new_img)\\nnew_img = new_img.reshape(28,28,1)\\nplt.imshow(new_img, cmap='gray')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justins code:"
      ],
      "metadata": {
        "id": "nvShI0YFGzgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "t3UjyGGOemqe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "#import tensorflow_probability as tfp\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, \\\n",
        "    LeakyReLU, Conv2DTranspose, Conv2D, Dropout, \\\n",
        "        Flatten, Reshape, ReLU, Input, Concatenate\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.python.data import Iterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import sys\n",
        "import multiprocessing\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "#import stacked_mnist\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "#tfd = tfp.distributions\n",
        "\n",
        "def make_directory(PATH):\n",
        "    if not os.path.exists(PATH):\n",
        "            os.mkdir(PATH)\n",
        "\n",
        "\n",
        "class AlphaGAN(object):\n",
        "    def __init__(self, opt):\n",
        "        self.opt = opt\n",
        "        self.batch_size = 1\n",
        "        self.noise_dim = 28*28\n",
        "        self.epsilon = 1e-8\n",
        "        self.alpha_d = float(opt.alpha_d)\n",
        "        self.alpha_g = float(opt.alpha_g)\n",
        "        self.seed = opt.seed\n",
        "        self.loss_type = opt.loss_type\n",
        "        self.dataset = opt.dataset\n",
        "        self.n_epochs = opt.n_epochs\n",
        "        self.gp = opt.gp\n",
        "        self.scores = np.zeros(self.n_epochs)\n",
        "        self.num_images = opt.num_images\n",
        "        self.gp_coef = opt.gp_coef\n",
        "        if self.dataset != 'cifar10':\n",
        "            self.num_images = 10\n",
        "        self.d_opt = Adam(2e-4, beta_1 = 0.5)\n",
        "        self.g_opt = Adam(2e-4, beta_1 = 0.5)\n",
        "        if self.dataset == 'cifar10':\n",
        "            self.noise_dim = 100\n",
        "        self.l1 = opt.l1\n",
        "        tf.random.set_seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "\n",
        "    def get_data(self):\n",
        "        if self.dataset == 'mnist':\n",
        "            (self.train_img, _), (self.test_img, _) = tf.keras.datasets.mnist.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 28, 28, 1)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 28, 28, 1)\n",
        "\n",
        "        elif self.dataset == 'cifar10':\n",
        "            (self.train_img, _), (self.test_img, _) = tf.keras.datasets.cifar10.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 32, 32, 3)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 32, 32, 3)\n",
        "\n",
        "        elif self.dataset == 'stacked-mnist':\n",
        "            (self.train_img, _), (self.test_img, _) = stacked_mnist.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 32, 32, 3)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 32, 32, 3)\n",
        "\n",
        "        elif self.dataset == 'mri':\n",
        "            # Iterate over all files in the tumor directory\n",
        "\n",
        "            tumor_dir = '/content/cleaned4/Training/notumor/'\n",
        "            tumor_training_images = []\n",
        "            for filename in os.listdir(tumor_dir):\n",
        "                if filename.endswith('.jpg'):  # Assuming images are in JPG format\n",
        "                    image_path = os.path.join(tumor_dir, filename)\n",
        "                    image = plt.imread(image_path, format='jpg')\n",
        "                    tumor_training_images.append(image)\n",
        "\n",
        "            # Convert the list of images to a NumPy array\n",
        "            self.train_img = np.asarray(tumor_training_images)\n",
        "\n",
        "            tumor_dir = '/content/cleaned4/Testing/notumor/'\n",
        "            tumor_testing_images = []\n",
        "            for filename in os.listdir(tumor_dir):\n",
        "                if filename.endswith('.jpg'):  # Assuming images are in JPG format\n",
        "                    image_path = os.path.join(tumor_dir, filename)\n",
        "                    image = plt.imread(image_path, format='jpg')\n",
        "                    tumor_testing_images.append(image)\n",
        "\n",
        "            # Convert the list of images to a NumPy array\n",
        "            self.test_img = np.asarray(tumor_testing_images)\n",
        "\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 28, 28, 1)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 28, 28, 1)\n",
        "\n",
        "          # self.train_img =  np.asarray([plt.imread(\"cleaned4/Training/notumor/Tr-noTr_0000.jpg\", format='jpg')])\n",
        "          # self.test_img = np.asarray([plt.imread(\"cleaned4/Testing/notumor/Te-noTr_0000.jpg\", format='jpg')])\n",
        "\n",
        "        self.real_mu, self.real_sigma = self.get_eval_metrics(self.train_img)\n",
        "        self.train_data, self.test_data = self.clean_data(self.train_img, train = True), self.clean_data(self.test_img, train = False)\n",
        "\n",
        "\n",
        "    def get_eval_metrics(self, data):\n",
        "        img_dims = data.shape\n",
        "        eval_img = data[np.random.choice(img_dims[0], 1, replace=False), :, :, :]\n",
        "        eval_img = eval_img.reshape(1, np.prod(img_dims[1:])).astype('float32') # CHANGE BACK TO 10000\n",
        "        eval_img = eval_img / 255.0\n",
        "        real_mu = eval_img.mean(axis = 0)\n",
        "        eval_img = np.transpose(eval_img)\n",
        "        real_sigma = np.cov(eval_img)\n",
        "        return real_mu, real_sigma\n",
        "\n",
        "    def clean_data(self, data, train):\n",
        "\n",
        "        new_data = data.astype('float32')\n",
        "        new_data = (new_data - 127.5) / 127.5\n",
        "        if train:\n",
        "            new_data = tf.data.Dataset.from_tensor_slices(new_data)\n",
        "            return new_data.shuffle(100000).batch(self.batch_size)\n",
        "        return new_data\n",
        "\n",
        "    def gen_loss_vanilla(self):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "        loss_expr =  bce(tf.ones_like(self.fake_predicted_labels), self.fake_predicted_labels)\n",
        "        if self.l1:\n",
        "            loss_expr = tf.math.abs(loss_expr - (-tf.math.log(2.0)))\n",
        "        return loss_expr\n",
        "\n",
        "    def gen_loss_vanilla_l1(self):\n",
        "        return tf.math.abs(self.gen_loss_vanilla() - (-tf.math.log(2.0)))\n",
        "\n",
        "\n",
        "    def gen_loss_alpha(self):\n",
        "        fake_expr = tf.math.pow(1 - self.fake_predicted_labels, ((self.alpha_g-1)/self.alpha_g)*tf.ones_like(self.fake_predicted_labels))\n",
        "        fake_loss = tf.math.reduce_mean(fake_expr)\n",
        "        loss_expr = (self.alpha_g/(self.alpha_g - 1))*(fake_loss - 2.0)\n",
        "        if self.l1:\n",
        "            equil_val = (self.alpha_g)/(self.alpha_g - 1)*(tf.math.pow(2.0, 1/self.alpha_g) - 2)\n",
        "            loss_expr = tf.math.abs(loss_expr - equil_val)\n",
        "        return loss_expr\n",
        "\n",
        "    def dis_loss_vanilla(self):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "        real_loss = bce(tf.ones_like(self.real_predicted_labels), self.real_predicted_labels)\n",
        "        fake_loss = bce(tf.zeros_like(self.fake_predicted_labels), self.fake_predicted_labels)\n",
        "        r1_penalty = 0\n",
        "        if self.gp:\n",
        "            gradients = tf.gradients(-tf.math.log(1 / self.real_predicted_labels - 1), [self.img])[0]\n",
        "            r1_penalty = tf.reduce_mean(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "        return real_loss + fake_loss + self.gp_coef*r1_penalty\n",
        "\n",
        "    def dis_loss_alpha(self):\n",
        "        real_expr = tf.math.pow(self.real_predicted_labels, ((self.alpha_d-1)/self.alpha_d)*tf.ones_like(self.real_predicted_labels))\n",
        "        real_loss = tf.math.reduce_mean(real_expr)\n",
        "        fake_expr = tf.math.pow(1 - self.fake_predicted_labels, ((self.alpha_d-1)/self.alpha_d)*tf.ones_like(self.fake_predicted_labels))\n",
        "        fake_loss = tf.math.reduce_mean(fake_expr)\n",
        "        r1_penalty = 0\n",
        "        if self.gp:\n",
        "            gradients = tf.gradients(-tf.math.log(1 / self.real_predicted_labels - 1), [self.img])[0]\n",
        "            r1_penalty = tf.reduce_mean(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "        loss_expr = -(self.alpha_d/(self.alpha_d - 1))*(real_loss + fake_loss - 2.0)\n",
        "\n",
        "\n",
        "        return loss_expr + self.gp_coef*r1_penalty\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        if self.dataset == 'mnist' or self.dataset == 'mri':\n",
        "\n",
        "            model.add(Dense(7 * 7 * 256, use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01), input_shape=(self.noise_dim,)))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Reshape((7, 7, 256)))\n",
        "\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh', use_bias=False,\n",
        "                                        kernel_initializer=RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "\n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'stacked-mnist':\n",
        "            model.add(Dense(256*4*4, input_shape=(self.noise_dim,)))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Reshape((4, 4, 256)))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(3, (3, 3), activation='tanh', padding = 'same'))\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def build_dq(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        if self.dataset == 'mnist' or self.dataset == 'mri':\n",
        "            model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "            model.add(LeakyReLU())\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "            model.add(LeakyReLU())\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dense(1, activation='sigmoid', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'stacked-mnist':\n",
        "            model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dropout(0.4))\n",
        "            model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        return model\n",
        "\n",
        "    def build_gan(self):\n",
        "        self.generator = self.build_generator()\n",
        "        self.discriminator = self.build_dq()\n",
        "        self.generator_loss = self.gen_loss_alpha\n",
        "        self.discriminator_loss = self.dis_loss_alpha\n",
        "        if self.alpha_d == 1.0:\n",
        "            self.discriminator_loss = self.dis_loss_vanilla\n",
        "        if self.alpha_g == 1.0:\n",
        "            self.generator_loss = self.gen_loss_vanilla\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        z = tf.random.normal([self.batch_size, self.noise_dim])\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape, tf.GradientTape() as q_tape:\n",
        "            self.discriminator.trainable = True\n",
        "            self.img = real_images\n",
        "            self.real_predicted_labels = self.discriminator(real_images, training = True)\n",
        "\n",
        "            self.generated_images = self.generator(z, training = True)\n",
        "            self.fake_predicted_labels = self.discriminator(self.generated_images, training = True)\n",
        "\n",
        "            self.dis_loss_value = self.discriminator_loss()\n",
        "            self.gen_loss_value = self.generator_loss()\n",
        "\n",
        "        dis_gradients = dis_tape.gradient(self.dis_loss_value, self.discriminator.trainable_variables)\n",
        "        self.d_opt.apply_gradients(zip(dis_gradients, self.discriminator.trainable_variables))\n",
        "        self.discriminator.trainable = False\n",
        "        gen_gradients = gen_tape.gradient(self.gen_loss_value, self.generator.trainable_variables)\n",
        "        self.g_opt.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        return self.dis_loss_value, self.gen_loss_value\n",
        "\n",
        "    def build_directory(self):\n",
        "        gan_name = 'AlphaGAN'\n",
        "        if self.alpha_d == 1.0 and self.alpha_g == 1.0:\n",
        "            gan_name = 'VanillaGAN'\n",
        "        '''\n",
        "        SEEDS = [123, 1600, 60677, 15859, 79878]\n",
        "        if self.dataset == 'mnist':\n",
        "            SEEDS = [123, 500, 1600, 199621, 60677, 20435, 15859, 33764, 79878, 36123]\n",
        "        '''\n",
        "        make_directory(gan_name)\n",
        "        make_directory(f'{gan_name}/{self.dataset}')\n",
        "        if gan_name == 'AlphaGAN':\n",
        "            make_directory(f'{gan_name}/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}')\n",
        "\n",
        "        subfolders = [f[0] for f in os.walk(f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}')]\n",
        "        folders = [f for f in subfolders if f.startswith(f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v')]\n",
        "\n",
        "        versions = [f.split('/v')[1] for f in folders]\n",
        "        versions = [int(v) for v in versions if v.isnumeric()]\n",
        "        version = 1\n",
        "        if versions:\n",
        "            version = max(versions) + 1\n",
        "        folder_created = False\n",
        "\n",
        "        while not folder_created:\n",
        "            self.path = f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v'+str(version)\n",
        "\n",
        "            try:\n",
        "                make_directory(self.path)\n",
        "                folder_created = True\n",
        "            except:\n",
        "                version += 1\n",
        "        '''\n",
        "\n",
        "        version = SEEDS.index(self.seed) + 1\n",
        "        if self.gp and self.l1:\n",
        "            version = version + 15 if self.dataset != 'mnist' else version + 30\n",
        "        elif self.gp:\n",
        "            version = version + 5 if self.dataset != 'mnist' else version + 10\n",
        "        elif self.l1:\n",
        "            version = version + 10 if self.dataset != 'mnist' else version + 20\n",
        "        '''\n",
        "        self.path = f'{gan_name}/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v'+str(version)\n",
        "        if gan_name == 'VanillaGAN':\n",
        "            self.path = f'{gan_name}/{self.dataset}/v'+str(version)\n",
        "\n",
        "        make_directory(self.path)\n",
        "        make_directory(self.path + '/metrics')\n",
        "        make_directory(self.path + '/metrics/accuracy')\n",
        "        make_directory(self.path + '/metrics/losses')\n",
        "        make_directory(self.path + '/img')\n",
        "        make_directory(self.path + '/models')\n",
        "\n",
        "        with open(self.path+'/description.txt', 'w') as f:\n",
        "            f.write(f'version={version}\\n')\n",
        "            for k, v in vars(self.opt).items():\n",
        "                f.write(f'{k}={v}')\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.get_data()\n",
        "        self.build_gan()\n",
        "        self.build_directory()\n",
        "        gen_loss_history = np.zeros(self.n_epochs)\n",
        "        dis_loss_history = np.zeros(self.n_epochs)\n",
        "        epoch_times = []\n",
        "        img_times = []\n",
        "        epochs_passed = 0\n",
        "        for epoch in range(1, self.n_epochs + 1):\n",
        "            print(f\"Epoch {epoch}\")\n",
        "            n_batches = 0\n",
        "            start_epoch = time.time()\n",
        "            for real_images in iter(self.train_data):\n",
        "\n",
        "                dis_loss_value, gen_loss_value = self.train_step(real_images)\n",
        "\n",
        "                gen_loss_history[epoch - 1] += gen_loss_value\n",
        "                dis_loss_history[epoch - 1] += dis_loss_value\n",
        "\n",
        "                n_batches += 1\n",
        "            gen_loss_history = gen_loss_history/n_batches\n",
        "            dis_loss_history = dis_loss_history/n_batches\n",
        "            end_epoch = time.time()\n",
        "            epoch_times.append(end_epoch - start_epoch)\n",
        "            self.evaluate(epoch)\n",
        "            start_img = time.time()\n",
        "            self.save_generated_images(epoch)\n",
        "            end_img = time.time()\n",
        "            img_times.append(end_img - start_img)\n",
        "            epochs_passed += 1\n",
        "            try:\n",
        "                self.scores[epoch - 1] = self.compute_fid()\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "                break\n",
        "\n",
        "\n",
        "        np.save(self.path + '/metrics/losses/gen_loss.npy', gen_loss_history)\n",
        "        np.save(self.path + '/metrics/losses/dis_loss.npy', dis_loss_history)\n",
        "\n",
        "        self.generator.save(self.path+ '/models/generator')\n",
        "        self.discriminator.save(self.path + '/models/discriminator')\n",
        "\n",
        "        time_df = pd.DataFrame({'epoch':list(range(1, epochs_passed + 1)),\n",
        "        'epoch_time':epoch_times, 'img_times':img_times})\n",
        "\n",
        "        time_df.to_pickle(self.path+'/times.pkl')\n",
        "        np.save(self.path + '/scores.npy', self.scores)\n",
        "        if epochs_passed == self.n_epochs:\n",
        "            for epoch in range(epochs_passed):\n",
        "                if epoch != np.nanargmin(self.scores):\n",
        "                    os.remove(self.path + '/img/predictions' + str(epoch + 1) + \".npy\")\n",
        "\n",
        "\n",
        "\n",
        "    def compute_fid(self):\n",
        "        fake_images = self.generator(tf.random.normal([10000, self.noise_dim]))\n",
        "        fake_images = fake_images.numpy()\n",
        "        if self.dataset == 'mnist' or self.dataset == 'mri':\n",
        "            fake_images = fake_images.reshape(10000, 28*28)\n",
        "        elif self.dataset == 'cifar10':\n",
        "            fake_images = fake_images.reshape(10000, 32*32*3)\n",
        "        elif self.dataset == 'stacked-mnist':\n",
        "            fake_images = fake_images.reshape(10000, 32*32*3)\n",
        "        fake_images = (fake_images * 127.5 + 127.5) / 255.0\n",
        "        fake_mu = fake_images.mean(axis=0)\n",
        "        fake_sigma = np.cov(np.transpose(fake_images))\n",
        "        covSqrt = sp.linalg.sqrtm(np.matmul(fake_sigma, self.real_sigma))\n",
        "        if np.iscomplexobj(covSqrt):\n",
        "            covSqrt = covSqrt.real\n",
        "        fidScore = np.linalg.norm(self.real_mu - fake_mu) + np.trace(self.real_sigma + fake_sigma - 2 * covSqrt)\n",
        "        return fidScore\n",
        "\n",
        "\n",
        "\n",
        "    def save_generated_images(self, epoch):\n",
        "        if epoch == 1:\n",
        "            self.z_eval = tf.random.normal([self.num_images, self.noise_dim])\n",
        "\n",
        "\n",
        "        imgs = self.generator(self.z_eval, training = False)\n",
        "        print(imgs.shape)\n",
        "\n",
        "        np.save(self.path+'/img/predictions' + str(epoch) + '.npy', imgs)\n",
        "\n",
        "        return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgzhqre-e707",
        "outputId": "95d5d7d7-8043-4af8-a17a-8faf28cdd72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-0cf912922758>:118: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  real_sigma = np.cov(eval_img)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2704: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2704: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "(10, 28, 28, 1)\n",
            "Epoch 2\n",
            "(10, 28, 28, 1)\n",
            "Epoch 3\n",
            "(10, 28, 28, 1)\n",
            "Epoch 4\n",
            "(10, 28, 28, 1)\n",
            "Epoch 5\n",
            "(10, 28, 28, 1)\n",
            "Epoch 6\n",
            "(10, 28, 28, 1)\n",
            "Epoch 7\n",
            "(10, 28, 28, 1)\n",
            "Epoch 8\n",
            "(10, 28, 28, 1)\n",
            "Epoch 9\n",
            "(10, 28, 28, 1)\n",
            "Epoch 10\n",
            "(10, 28, 28, 1)\n",
            "Epoch 11\n",
            "(10, 28, 28, 1)\n",
            "Epoch 12\n",
            "(10, 28, 28, 1)\n",
            "Epoch 13\n",
            "(10, 28, 28, 1)\n",
            "Epoch 14\n",
            "(10, 28, 28, 1)\n",
            "Epoch 15\n",
            "(10, 28, 28, 1)\n",
            "Epoch 16\n",
            "(10, 28, 28, 1)\n",
            "Epoch 17\n",
            "(10, 28, 28, 1)\n",
            "Epoch 18\n",
            "(10, 28, 28, 1)\n",
            "Epoch 19\n",
            "(10, 28, 28, 1)\n",
            "Epoch 20\n",
            "(10, 28, 28, 1)\n",
            "Epoch 21\n",
            "(10, 28, 28, 1)\n",
            "Epoch 22\n",
            "(10, 28, 28, 1)\n",
            "Epoch 23\n",
            "(10, 28, 28, 1)\n",
            "Epoch 24\n",
            "(10, 28, 28, 1)\n",
            "Epoch 25\n",
            "(10, 28, 28, 1)\n",
            "Epoch 26\n",
            "(10, 28, 28, 1)\n",
            "Epoch 27\n",
            "(10, 28, 28, 1)\n",
            "Epoch 28\n",
            "(10, 28, 28, 1)\n",
            "Epoch 29\n",
            "(10, 28, 28, 1)\n",
            "Epoch 30\n",
            "(10, 28, 28, 1)\n",
            "Epoch 31\n",
            "(10, 28, 28, 1)\n",
            "Epoch 32\n",
            "(10, 28, 28, 1)\n",
            "Epoch 33\n",
            "(10, 28, 28, 1)\n",
            "Epoch 34\n",
            "(10, 28, 28, 1)\n",
            "Epoch 35\n",
            "(10, 28, 28, 1)\n",
            "Epoch 36\n",
            "(10, 28, 28, 1)\n",
            "Epoch 37\n",
            "(10, 28, 28, 1)\n",
            "Epoch 38\n",
            "(10, 28, 28, 1)\n",
            "Epoch 39\n",
            "(10, 28, 28, 1)\n",
            "Epoch 40\n",
            "(10, 28, 28, 1)\n",
            "Epoch 41\n",
            "(10, 28, 28, 1)\n",
            "Epoch 42\n",
            "(10, 28, 28, 1)\n",
            "Epoch 43\n",
            "(10, 28, 28, 1)\n",
            "Epoch 44\n",
            "(10, 28, 28, 1)\n",
            "Epoch 45\n",
            "(10, 28, 28, 1)\n",
            "Epoch 46\n",
            "(10, 28, 28, 1)\n",
            "Epoch 47\n",
            "(10, 28, 28, 1)\n",
            "Epoch 48\n",
            "(10, 28, 28, 1)\n",
            "Epoch 49\n",
            "(10, 28, 28, 1)\n",
            "Epoch 50\n",
            "(10, 28, 28, 1)\n",
            "Epoch 51\n",
            "(10, 28, 28, 1)\n",
            "Epoch 52\n",
            "(10, 28, 28, 1)\n",
            "Epoch 53\n",
            "(10, 28, 28, 1)\n",
            "Epoch 54\n",
            "(10, 28, 28, 1)\n",
            "Epoch 55\n",
            "(10, 28, 28, 1)\n",
            "Epoch 56\n",
            "(10, 28, 28, 1)\n",
            "Epoch 57\n",
            "(10, 28, 28, 1)\n",
            "Epoch 58\n",
            "(10, 28, 28, 1)\n",
            "Epoch 59\n",
            "(10, 28, 28, 1)\n",
            "Epoch 60\n",
            "(10, 28, 28, 1)\n",
            "Epoch 61\n",
            "(10, 28, 28, 1)\n",
            "Epoch 62\n",
            "(10, 28, 28, 1)\n",
            "Epoch 63\n",
            "(10, 28, 28, 1)\n",
            "Epoch 64\n",
            "(10, 28, 28, 1)\n",
            "Epoch 65\n",
            "(10, 28, 28, 1)\n",
            "Epoch 66\n",
            "(10, 28, 28, 1)\n",
            "Epoch 67\n",
            "(10, 28, 28, 1)\n",
            "Epoch 68\n",
            "(10, 28, 28, 1)\n",
            "Epoch 69\n",
            "(10, 28, 28, 1)\n",
            "Epoch 70\n",
            "(10, 28, 28, 1)\n",
            "Epoch 71\n",
            "(10, 28, 28, 1)\n",
            "Epoch 72\n",
            "(10, 28, 28, 1)\n",
            "Epoch 73\n",
            "(10, 28, 28, 1)\n",
            "Epoch 74\n",
            "(10, 28, 28, 1)\n",
            "Epoch 75\n",
            "(10, 28, 28, 1)\n",
            "Epoch 76\n",
            "(10, 28, 28, 1)\n",
            "Epoch 77\n",
            "(10, 28, 28, 1)\n",
            "Epoch 78\n",
            "(10, 28, 28, 1)\n",
            "Epoch 79\n",
            "(10, 28, 28, 1)\n",
            "Epoch 80\n",
            "(10, 28, 28, 1)\n",
            "Epoch 81\n",
            "(10, 28, 28, 1)\n",
            "Epoch 82\n",
            "(10, 28, 28, 1)\n",
            "Epoch 83\n",
            "(10, 28, 28, 1)\n",
            "Epoch 84\n",
            "(10, 28, 28, 1)\n",
            "Epoch 85\n",
            "(10, 28, 28, 1)\n",
            "Epoch 86\n",
            "(10, 28, 28, 1)\n",
            "Epoch 87\n",
            "(10, 28, 28, 1)\n",
            "Epoch 88\n",
            "(10, 28, 28, 1)\n",
            "Epoch 89\n",
            "(10, 28, 28, 1)\n",
            "Epoch 90\n",
            "(10, 28, 28, 1)\n",
            "Epoch 91\n",
            "(10, 28, 28, 1)\n",
            "Epoch 92\n",
            "(10, 28, 28, 1)\n",
            "Epoch 93\n",
            "(10, 28, 28, 1)\n",
            "Epoch 94\n",
            "(10, 28, 28, 1)\n",
            "Epoch 95\n",
            "(10, 28, 28, 1)\n",
            "Epoch 96\n",
            "(10, 28, 28, 1)\n",
            "Epoch 97\n",
            "(10, 28, 28, 1)\n",
            "Epoch 98\n",
            "(10, 28, 28, 1)\n",
            "Epoch 99\n",
            "(10, 28, 28, 1)\n",
            "Epoch 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28, 28, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "#from keras.datasets import mnist\n",
        "import gc\n",
        "import argparse\n",
        "\n",
        "class Option():\n",
        "    \"\"\"\n",
        "    Empty class to hold the gan options\n",
        "    \"\"\"\n",
        "    def __init__(self, gan_type, alpha, seed, c_type, n_epochs, dataset, loss_type, lambda_d, lambda_c, num_images, gp, gen_lr, dis_lr, q_lr, gp_coef, alpha_d, alpha_g, k, shifted, l1):\n",
        "        self.gan_type = gan_type\n",
        "        self.alpha = alpha\n",
        "        self.seed = seed\n",
        "        self.c_type = c_type\n",
        "        self.n_epochs = n_epochs\n",
        "        self.dataset = dataset\n",
        "        self.loss_type = loss_type\n",
        "        self.lambda_d = lambda_d\n",
        "        self.lambda_c = lambda_c\n",
        "        self.num_images = num_images\n",
        "        self.gp = gp\n",
        "        self.gen_lr = gen_lr\n",
        "        self.dis_lr = dis_lr\n",
        "        self.q_lr = q_lr\n",
        "        self.gp_coef = gp_coef\n",
        "        self.alpha_d = alpha_d\n",
        "        self.alpha_g = alpha_g\n",
        "        self.k = k\n",
        "        self.shifted = shifted\n",
        "        self.l1 = l1\n",
        "        return\n",
        "#set up options\n",
        "opts = Option(gan_type='alpha', alpha=3.0, seed=42, c_type='discrete', n_epochs=100, dataset='mri', loss_type='vanilla', lambda_d=1.0, lambda_c=0.1, num_images= 300, gp=False, gen_lr=0.0002, dis_lr=0.0002, q_lr=0.0002, gp_coef=5.0, alpha_d=3.0, alpha_g=3.0, k=2.0, shifted=False, l1=False)\n",
        "\n",
        "# Define an alphagan to test\n",
        "gan = AlphaGAN(opts)\n",
        "\n",
        "# sets data to mnist and configures it for the gan\n",
        "gan.dataset = 'mri'\n",
        "gan.get_data()\n",
        "\n",
        "\n",
        "#build the generative network\n",
        "gan.build_gan()\n",
        "\n",
        "gan.train()\n",
        "\n",
        "gan.save_generated_images(1)\n",
        "\n",
        "# while testing not going to include fid computations\n",
        "# gan.compute_fid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "auYhEuVnfrG7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "16fbe735-fede-44ac-abd7-5fa9bfc1320c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = \"/content/AlphaGAN/mri/alpha-d3.0-g3.0/v9/img/predictions1.npy\"\n",
        "\n",
        "# Load the numpy file\n",
        "img_array = np.load(filename, allow_pickle=True)\n",
        "\n",
        "# Normalize the data to [0, 1]\n",
        "img_array_normalized = (img_array - img_array.min()) / (img_array.max() - img_array.min())\n",
        "\n",
        "# Add the channel dimension back\n",
        "img_array_normalized_with_channel = img_array_normalized[0, :, :, 0]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img_array_normalized_with_channel, cmap=\"gray\")\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = plt.imread(\"cleaned/Training/notumor/Tr-noTr_0000.jpg\", format='jpg')"
      ],
      "metadata": {
        "id": "XCl3PekMfqZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPp2eM0pl89O",
        "outputId": "8e9620d3-c2fe-42db-f0a6-c13554571a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3,   3,   3],\n",
              "       [  2,   2,   2],\n",
              "       [  5,   5,   5],\n",
              "       [  4,   4,   4],\n",
              "       [  0,   0,   0],\n",
              "       [  4,   4,   4],\n",
              "       [  2,   2,   2],\n",
              "       [  2,   2,   2],\n",
              "       [  5,   5,   5],\n",
              "       [  4,   4,   4],\n",
              "       [  2,   2,   2],\n",
              "       [ 17,  17,  17],\n",
              "       [136, 136, 136],\n",
              "       [ 99,  99,  99],\n",
              "       [ 34,  34,  34],\n",
              "       [  1,   1,   1],\n",
              "       [  3,   3,   3],\n",
              "       [  4,   4,   4],\n",
              "       [  4,   4,   4],\n",
              "       [  9,   9,   9],\n",
              "       [  3,   3,   3],\n",
              "       [  0,   0,   0],\n",
              "       [  5,   5,   5],\n",
              "       [  6,   6,   6],\n",
              "       [  4,   4,   4],\n",
              "       [  6,   6,   6],\n",
              "       [  0,   0,   0],\n",
              "       [  0,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "GbaN4X4jmBzm",
        "outputId": "f1eed416-4907-4fa2-a1af-4e05b9afd9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'tuple' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-38a24e5ce95d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLxlDylfmQMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}